{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def tag(x):\n",
    "    tokens = x.split()\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tags = [x[1] for x in tags]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_integers(filename):\n",
    "    with open(filename) as f:\n",
    "        return [int(x) for x in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constituency_parsing 8 3\n",
      "constituency_parsing 1 4\n",
      "constituency_parsing 5 4\n",
      "constituency_parsing 7 4\n",
      "constituency_parsing 4 3\n",
      "constituency_parsing 6 4\n",
      "constituency_parsing 2 3\n",
      "constituency_parsing 3 4\n",
      "constituency_parsing 0 3\n",
      "entity_linking 16 3\n",
      "entity_linking 13 4\n",
      "entity_linking 8 4\n",
      "entity_linking 9 3\n",
      "entity_linking 1 3\n",
      "entity_linking 5 4\n",
      "entity_linking 11 5\n",
      "entity_linking 14 3\n",
      "entity_linking 7 3\n",
      "entity_linking 4 5\n",
      "entity_linking 6 4\n",
      "entity_linking 10 3\n",
      "entity_linking 2 4\n",
      "entity_linking 3 3\n",
      "entity_linking 15 5\n",
      "entity_linking 12 5\n",
      "entity_linking 0 5\n",
      "face_detection 16 3\n",
      "face_detection 13 6\n",
      "face_detection 8 4\n",
      "face_detection 9 3\n",
      "face_detection 1 5\n",
      "face_detection 21 4\n",
      "face_detection 5 4\n",
      "face_detection 11 5\n",
      "face_detection 14 4\n",
      "face_detection 7 6\n",
      "face_detection 19 4\n",
      "face_detection 20 3\n",
      "face_detection 18 4\n",
      "face_detection 4 4\n",
      "face_detection 6 5\n",
      "face_detection 10 6\n",
      "face_detection 17 4\n",
      "face_detection 2 4\n",
      "face_detection 3 5\n",
      "face_detection 15 6\n",
      "face_detection 12 3\n",
      "face_detection 0 4\n",
      "coreference_resolution 8 5\n",
      "coreference_resolution 9 5\n",
      "coreference_resolution 1 4\n",
      "coreference_resolution 5 5\n",
      "coreference_resolution 7 3\n",
      "coreference_resolution 4 6\n",
      "coreference_resolution 6 4\n",
      "coreference_resolution 2 3\n",
      "coreference_resolution 3 3\n",
      "coreference_resolution 0 3\n",
      "dependency_parsing 8 3\n",
      "dependency_parsing 1 5\n",
      "dependency_parsing 5 4\n",
      "dependency_parsing 7 3\n",
      "dependency_parsing 4 3\n",
      "dependency_parsing 6 4\n",
      "dependency_parsing 2 3\n",
      "dependency_parsing 3 5\n",
      "dependency_parsing 0 5\n",
      "face_alignment 16 7\n",
      "face_alignment 13 5\n",
      "face_alignment 8 5\n",
      "face_alignment 9 5\n",
      "face_alignment 1 5\n",
      "face_alignment 5 6\n",
      "face_alignment 11 3\n",
      "face_alignment 14 3\n",
      "face_alignment 7 6\n",
      "face_alignment 18 4\n",
      "face_alignment 4 4\n",
      "face_alignment 6 5\n",
      "face_alignment 10 5\n",
      "face_alignment 17 6\n",
      "face_alignment 2 5\n",
      "face_alignment 3 5\n",
      "face_alignment 15 4\n",
      "face_alignment 12 5\n",
      "face_alignment 0 3\n",
      "natural_language_inference 16 4\n",
      "natural_language_inference 13 4\n",
      "natural_language_inference 27 3\n",
      "natural_language_inference 8 4\n",
      "natural_language_inference 9 4\n",
      "natural_language_inference 25 5\n",
      "natural_language_inference 26 5\n",
      "natural_language_inference 1 5\n",
      "natural_language_inference 21 5\n",
      "natural_language_inference 5 3\n",
      "natural_language_inference 11 4\n",
      "natural_language_inference 23 4\n",
      "natural_language_inference 24 4\n",
      "natural_language_inference 14 4\n",
      "natural_language_inference 7 3\n",
      "natural_language_inference 28 3\n",
      "natural_language_inference 19 4\n",
      "natural_language_inference 20 3\n",
      "natural_language_inference 18 3\n",
      "natural_language_inference 4 5\n",
      "natural_language_inference 6 3\n",
      "natural_language_inference 10 4\n",
      "natural_language_inference 29 3\n",
      "natural_language_inference 17 5\n",
      "natural_language_inference 2 4\n",
      "natural_language_inference 3 4\n",
      "natural_language_inference 15 4\n",
      "natural_language_inference 22 6\n",
      "natural_language_inference 30 3\n",
      "natural_language_inference 31 3\n",
      "natural_language_inference 12 5\n",
      "natural_language_inference 0 3\n",
      "document_classification 16 5\n",
      "document_classification 13 3\n",
      "document_classification 8 4\n",
      "document_classification 9 7\n",
      "document_classification 1 5\n",
      "document_classification 5 5\n",
      "document_classification 11 4\n",
      "document_classification 14 4\n",
      "document_classification 7 3\n",
      "document_classification 19 4\n",
      "document_classification 20 3\n",
      "document_classification 18 4\n",
      "document_classification 4 6\n",
      "document_classification 6 3\n",
      "document_classification 10 6\n",
      "document_classification 17 4\n",
      "document_classification 2 4\n",
      "document_classification 3 4\n",
      "document_classification 15 5\n",
      "document_classification 12 6\n",
      "document_classification 0 3\n",
      "data-to-text_generation 1 4\n",
      "data-to-text_generation 5 5\n",
      "data-to-text_generation 4 4\n",
      "data-to-text_generation 6 4\n",
      "data-to-text_generation 2 3\n",
      "data-to-text_generation 3 3\n",
      "data-to-text_generation 0 6\n",
      "hypernym_discovery 8 3\n",
      "hypernym_discovery 1 4\n",
      "hypernym_discovery 5 4\n",
      "hypernym_discovery 7 3\n",
      "hypernym_discovery 4 3\n",
      "hypernym_discovery 6 3\n",
      "hypernym_discovery 2 3\n",
      "hypernym_discovery 3 5\n",
      "hypernym_discovery 0 3\n"
     ]
    }
   ],
   "source": [
    "path = \"./Best_Submission/submission/*/*\"\n",
    "directory = glob.glob(path)\n",
    "position = len(path)-3\n",
    "topics, paper_ID, info_units, triplets = [], [], [], []\n",
    "sub, pred, obj = [], [], []\n",
    "for dir in directory:\n",
    "    pos = dir.find('/', position)\n",
    "    topic = dir[position:pos]\n",
    "    ID = dir[pos+1:len(dir)]\n",
    "    path_dir = \"\".join((dir,\"/triples/*.txt\"))\n",
    "    files = glob.glob(path_dir)\n",
    "    print(topic, ID, len(files))\n",
    "    for file in files:\n",
    "        info_unit = file[len(dir)+9:-4]\n",
    "        #print(info_unit)\n",
    "        with open(file, encoding='ISO-8859-1') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "        for line in lines:\n",
    "            triplet = line[1:len(line)-1]\n",
    "            item = triplet.split('||')\n",
    "            topics.append(topic)\n",
    "            paper_ID.append(ID)\n",
    "            info_units.append(info_unit)\n",
    "            triplets.append(triplet)\n",
    "            sub.append(item[0])\n",
    "            pred.append(item[1])\n",
    "            obj.append(item[2])\n",
    "df = pd.DataFrame({\"topic\" : topics, \"paper_ID\" : paper_ID, \"info_units\": info_units, \"triplets\" : triplets, \n",
    "                   'sub' : sub, 'pred': pred, 'obj' : obj})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>paper_ID</th>\n",
       "      <th>info_units</th>\n",
       "      <th>triplets</th>\n",
       "      <th>sub</th>\n",
       "      <th>pred</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>results</td>\n",
       "      <td>Contribution||has||Results</td>\n",
       "      <td>Contribution</td>\n",
       "      <td>has</td>\n",
       "      <td>Results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>results</td>\n",
       "      <td>Results||has||Results</td>\n",
       "      <td>Results</td>\n",
       "      <td>has</td>\n",
       "      <td>Results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>results</td>\n",
       "      <td>Results||has||English ( WSJ )</td>\n",
       "      <td>Results</td>\n",
       "      <td>has</td>\n",
       "      <td>English ( WSJ )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>results</td>\n",
       "      <td>test score||of||93.55 F1</td>\n",
       "      <td>test score</td>\n",
       "      <td>of</td>\n",
       "      <td>93.55 F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>results</td>\n",
       "      <td>93.55 F1||for||CharLSTM parser</td>\n",
       "      <td>93.55 F1</td>\n",
       "      <td>for</td>\n",
       "      <td>CharLSTM parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9458</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>research-problem</td>\n",
       "      <td>Contribution||has research problem||generalise</td>\n",
       "      <td>Contribution</td>\n",
       "      <td>has research problem</td>\n",
       "      <td>generalise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9459</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>research-problem</td>\n",
       "      <td>Contribution||has research problem||more easily</td>\n",
       "      <td>Contribution</td>\n",
       "      <td>has research problem</td>\n",
       "      <td>more easily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9460</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>research-problem</td>\n",
       "      <td>Contribution||has research problem||unseen hyp...</td>\n",
       "      <td>Contribution</td>\n",
       "      <td>has research problem</td>\n",
       "      <td>unseen hypernym - hyponym pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9461</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>research-problem</td>\n",
       "      <td>Contribution||has research problem||Unsupervis...</td>\n",
       "      <td>Contribution</td>\n",
       "      <td>has research problem</td>\n",
       "      <td>Unsupervised Hypernym Discovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>research-problem</td>\n",
       "      <td>Contribution||has research problem||hypernym d...</td>\n",
       "      <td>Contribution</td>\n",
       "      <td>has research problem</td>\n",
       "      <td>hypernym discovery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9463 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     topic paper_ID        info_units  \\\n",
       "0     constituency_parsing        8           results   \n",
       "1     constituency_parsing        8           results   \n",
       "2     constituency_parsing        8           results   \n",
       "3     constituency_parsing        8           results   \n",
       "4     constituency_parsing        8           results   \n",
       "...                    ...      ...               ...   \n",
       "9458    hypernym_discovery        0  research-problem   \n",
       "9459    hypernym_discovery        0  research-problem   \n",
       "9460    hypernym_discovery        0  research-problem   \n",
       "9461    hypernym_discovery        0  research-problem   \n",
       "9462    hypernym_discovery        0  research-problem   \n",
       "\n",
       "                                               triplets           sub  \\\n",
       "0                            Contribution||has||Results  Contribution   \n",
       "1                                 Results||has||Results       Results   \n",
       "2                         Results||has||English ( WSJ )       Results   \n",
       "3                              test score||of||93.55 F1    test score   \n",
       "4                        93.55 F1||for||CharLSTM parser      93.55 F1   \n",
       "...                                                 ...           ...   \n",
       "9458     Contribution||has research problem||generalise  Contribution   \n",
       "9459    Contribution||has research problem||more easily  Contribution   \n",
       "9460  Contribution||has research problem||unseen hyp...  Contribution   \n",
       "9461  Contribution||has research problem||Unsupervis...  Contribution   \n",
       "9462  Contribution||has research problem||hypernym d...  Contribution   \n",
       "\n",
       "                      pred                              obj  \n",
       "0                      has                          Results  \n",
       "1                      has                          Results  \n",
       "2                      has                  English ( WSJ )  \n",
       "3                       of                         93.55 F1  \n",
       "4                      for                  CharLSTM parser  \n",
       "...                    ...                              ...  \n",
       "9458  has research problem                       generalise  \n",
       "9459  has research problem                      more easily  \n",
       "9460  has research problem  unseen hypernym - hyponym pairs  \n",
       "9461  has research problem  Unsupervised Hypernym Discovery  \n",
       "9462  has research problem               hypernym discovery  \n",
       "\n",
       "[9463 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results               2405\n",
       "model                 2169\n",
       "experimental-setup    1458\n",
       "experiments            792\n",
       "ablation-analysis      592\n",
       "hyperparameters        564\n",
       "approach               526\n",
       "research-problem       517\n",
       "baselines              365\n",
       "dataset                 38\n",
       "code                    37\n",
       "Name: info_units, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['info_units'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset_TaskC/Test_Triplets.csv\", index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
