{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv(\"Triplets_All_Results/test_results_info_A.csv\")\n",
    "dfb = pd.read_csv(\"Triplets_All_Results/test_results_info_B.csv\")\n",
    "dfc = pd.read_csv(\"Triplets_All_Results/test_results_info_C.csv\")\n",
    "dfd = pd.read_csv(\"Triplets_All_Results/test_results_info_D.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['topic', 'paper_ID', 'sentence_ID', 'info-unit', 'sentence',\n",
       "       'start_sub', 'end_sub', 'sub', 'labels_sub', 'sub_num', 'start_pred',\n",
       "       'end_pred', 'pred', 'labels_pred', 'pred_num', 'start_obj', 'end_obj',\n",
       "       'obj', 'labels_obj', 'obj_num', 'input', '_merge', 'labels', 'predict'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = dfa[dfa['predict'] == 1][['topic', 'paper_ID', 'sentence_ID', 'info-unit', 'sub', 'pred', 'obj']]\n",
    "dfb = dfb[dfb['predict'] == 1][['topic', 'paper_ID', 'sentence_ID', 'info-unit', 'sub', 'pred', 'obj']]\n",
    "dfc = dfc[dfc['predict'] == 1][['topic', 'paper_ID', 'sentence_ID', 'info-unit', 'sub', 'pred', 'obj']]\n",
    "dfd = dfd[dfd['predict'] == 1][['topic', 'paper_ID', 'sentence_ID', 'info-unit', 'sub', 'pred', 'obj']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_case(x):\n",
    "    x = x[0].upper()+x[1:]\n",
    "    return x\n",
    "dfc['sub'] = dfc['sub'].apply(upper_case)\n",
    "dfd['sub'] = dfd['sub'].apply(upper_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfa)+len(dfb)+len(dfc)+len(dfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dfa, dfb, dfc, dfd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('has', inplace=True)\n",
    "df.sort_values(by = ['topic', 'paper_ID', 'info-unit', 'sentence_ID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Triplets_All_Results/test_results_info.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Triplets_All_Results/test_results_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>paper_ID</th>\n",
       "      <th>sentence_ID</th>\n",
       "      <th>info-unit</th>\n",
       "      <th>sub</th>\n",
       "      <th>pred</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>approach</td>\n",
       "      <td>RNNGs</td>\n",
       "      <td>operate via</td>\n",
       "      <td>recursive syntactic process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>approach</td>\n",
       "      <td>recursive syntactic process</td>\n",
       "      <td>reminiscent of</td>\n",
       "      <td>probabilistic context - free grammar generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>approach</td>\n",
       "      <td>Approach</td>\n",
       "      <td>has</td>\n",
       "      <td>RNNGs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>approach</td>\n",
       "      <td>two variants</td>\n",
       "      <td>of</td>\n",
       "      <td>algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>approach</td>\n",
       "      <td>Approach</td>\n",
       "      <td>give</td>\n",
       "      <td>two variants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8307</th>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>31</td>\n",
       "      <td>187</td>\n",
       "      <td>results</td>\n",
       "      <td>Results</td>\n",
       "      <td>has</td>\n",
       "      <td>SAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>31</td>\n",
       "      <td>192</td>\n",
       "      <td>results</td>\n",
       "      <td>All of the MANNs</td>\n",
       "      <td>able to</td>\n",
       "      <td>perform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8309</th>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>31</td>\n",
       "      <td>192</td>\n",
       "      <td>results</td>\n",
       "      <td>much better</td>\n",
       "      <td>than</td>\n",
       "      <td>chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8310</th>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>31</td>\n",
       "      <td>192</td>\n",
       "      <td>results</td>\n",
       "      <td>perform</td>\n",
       "      <td>has</td>\n",
       "      <td>much better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>31</td>\n",
       "      <td>192</td>\n",
       "      <td>results</td>\n",
       "      <td>Results</td>\n",
       "      <td>has</td>\n",
       "      <td>All of the MANNs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8312 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           topic  paper_ID  sentence_ID info-unit  \\\n",
       "0           constituency_parsing         0           13  approach   \n",
       "1           constituency_parsing         0           13  approach   \n",
       "2           constituency_parsing         0           13  approach   \n",
       "3           constituency_parsing         0           15  approach   \n",
       "4           constituency_parsing         0           15  approach   \n",
       "...                          ...       ...          ...       ...   \n",
       "8307  natural_language_inference        31          187   results   \n",
       "8308  natural_language_inference        31          192   results   \n",
       "8309  natural_language_inference        31          192   results   \n",
       "8310  natural_language_inference        31          192   results   \n",
       "8311  natural_language_inference        31          192   results   \n",
       "\n",
       "                              sub            pred  \\\n",
       "0                           RNNGs     operate via   \n",
       "1     recursive syntactic process  reminiscent of   \n",
       "2                        Approach             has   \n",
       "3                    two variants              of   \n",
       "4                        Approach            give   \n",
       "...                           ...             ...   \n",
       "8307                      Results             has   \n",
       "8308             All of the MANNs         able to   \n",
       "8309                  much better            than   \n",
       "8310                      perform             has   \n",
       "8311                      Results             has   \n",
       "\n",
       "                                                  obj  \n",
       "0                         recursive syntactic process  \n",
       "1     probabilistic context - free grammar generation  \n",
       "2                                               RNNGs  \n",
       "3                                           algorithm  \n",
       "4                                        two variants  \n",
       "...                                               ...  \n",
       "8307                                              SAM  \n",
       "8308                                          perform  \n",
       "8309                                           chance  \n",
       "8310                                      much better  \n",
       "8311                                 All of the MANNs  \n",
       "\n",
       "[8312 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv(\"Dataset_TaskC/Test_Results_TaskC2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_code = df_temp[(df_temp['info-unit'].str.lower() == 'code')]\n",
    "df_code.to_csv(\"test_results_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_research = df_temp[(df_temp['info-unit'].str.lower() == 'research-problem')]\n",
    "df_research.to_csv(\"test_results_research.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ammaar/Desktop/submission_triplets_4\n"
     ]
    }
   ],
   "source": [
    "cd submission_triplets_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_code)):\n",
    "    task = df_code.iloc[i,0]\n",
    "    pid = df_code.iloc[i,1]\n",
    "    phrases = df_code.iloc[i,7]\n",
    "    path = task + \"/\" + str(pid) + \"/triples/code.txt\"\n",
    "    triplet = \"(Contribution||Code||\"  + phrases + \")\\n\"\n",
    "    with open(path, mode='at', encoding='utf-8') as file:\n",
    "        file.write(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_research)):\n",
    "    task = df_research.iloc[i,0]\n",
    "    pid = df_research.iloc[i,1]\n",
    "    phrases = df_research.iloc[i,7]\n",
    "    path = task + \"/\" + str(pid) + \"/triples/research-problem.txt\"\n",
    "    triplet = \"(Contribution||has research problem||\"  + phrases + \")\\n\"\n",
    "    with open(path, mode='at', encoding='utf-8') as file:\n",
    "        file.write(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    task = df.iloc[i,0]\n",
    "    pid = df.iloc[i,1]\n",
    "    info = df.iloc[i,3]\n",
    "    sub = df.loc[i, \"sub\"]\n",
    "    pred = df.loc[i, \"pred\"]\n",
    "    obj = df.loc[i, \"obj\"]\n",
    "    path = task + \"/\" + str(pid) + \"/triples/\" + info + \".txt\"\n",
    "    triplet = \"(\" + sub + \"||\" + pred + \"||\" + obj + \")\\n\"\n",
    "    contribution = \"(Contribution||has||\" + info[0].upper() + info[1:] + \")\\n\"\n",
    "    if(not exists(path)):\n",
    "        with open(path, mode='wt', encoding='utf-8') as file:\n",
    "            file.write(contribution)\n",
    "    with open(path, mode='at', encoding='utf-8') as file:\n",
    "            file.write(triplet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
