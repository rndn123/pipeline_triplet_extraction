{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval as load\n",
    "def NER_format(file, shift = 0):\n",
    "    df = pd.read_csv(file)\n",
    "    words = []\n",
    "    sentence_id = []\n",
    "    labels = []\n",
    "    pos_tag = []\n",
    "    for i in range(len(df)):\n",
    "        word = load(df.iloc[i,4])\n",
    "        BIO = load(df.iloc[i,5])\n",
    "        pos = load(df.iloc[i,6])\n",
    "        sentence_id.extend([i+shift]*len(word))\n",
    "        words.extend(word)\n",
    "        labels.extend(BIO)\n",
    "        pos_tag.extend(pos)\n",
    "    return sentence_id, words, labels, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_id, words, labels, pos_tag = NER_format(\"Dataset_TaskB/Training_Phrases.csv\")\n",
    "df1 = pd.DataFrame({\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels, \"pos_tag\" : pos_tag})\n",
    "df1.dropna(subset = ['words', 'labels'], inplace = True)\n",
    "df1.to_csv(\"Dataset_TaskB/NCG_Train.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_id, words, labels, pos_tag = NER_format(\"Dataset_TaskB/Trial_Phrases.csv\")\n",
    "df2 = pd.DataFrame({\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels, \"pos_tag\" : pos_tag})\n",
    "df2.dropna(subset = ['words', 'labels'], inplace = True)\n",
    "df2.to_csv(\"Dataset_TaskB/NCG_Valid.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(x):\n",
    "    tokens = x.split()\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tags = [x[1] for x in tags]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"sciERC_raw/raw_data/*.txt\"\n",
    "files = glob.glob(path)\n",
    "sentence_id, sentence, list_words, BIO, pos_tag, length = [], [], [], [], [], []\n",
    "for file1 in files:\n",
    "    file2 = file1[0:-4] + \".ann\"\n",
    "    with open(file1, encoding='latin-1') as f:\n",
    "        lines = f.readlines()\n",
    "    sent = lines[-1].strip()\n",
    "    with open(file2, encoding='latin-1') as f:\n",
    "        lines = f.readlines()\n",
    "    start_index = []\n",
    "    end_index = []\n",
    "    for line in lines:\n",
    "        item = line.split()\n",
    "        if(len(item) < 5 or item[0][0] != 'T'):\n",
    "            continue\n",
    "        start_index.append(int(item[2]))\n",
    "        end_index.append(int(item[3]))\n",
    "    start_index.sort()\n",
    "    end_index.sort()\n",
    "    words = sent.split()\n",
    "    sent_id = file1[20:-4]\n",
    "    cur, index = 0, 0\n",
    "    labels = []\n",
    "    for i, word in enumerate(words):\n",
    "        if(index<len(start_index) and cur > end_index[index]):\n",
    "            index += 1\n",
    "        if(index >= len(start_index)):\n",
    "            labels.append('O')\n",
    "            continue\n",
    "        if(cur >= start_index[index] and i==0):\n",
    "            labels.append('B')\n",
    "            continue\n",
    "        if(cur >= start_index[index] and i>0 and labels[i-1] == 'O'):\n",
    "            labels.append('B')\n",
    "        elif (cur >= start_index[index]):\n",
    "            labels.append('I')\n",
    "        else:\n",
    "            labels.append('O')\n",
    "        cur = cur + 1 + len(word)\n",
    "    pos = tag(sent)\n",
    "    sentence_id.append(sent_id)\n",
    "    sentence.append(sent)\n",
    "    list_words.append(words)\n",
    "    BIO.append(labels)\n",
    "    pos_tag.append(pos)\n",
    "    length.append(len(words))\n",
    "df_phrase = pd.DataFrame({'sentence_id': sentence_id, 'sentence' : sentence, 'words': list_words, \n",
    "                          'BIO' : BIO, 'POS' : pos_tag, 'length' : length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "      <th>BIO</th>\n",
       "      <th>POS</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N03-1004</td>\n",
       "      <td>Motivated by the success of  ensemble methods ...</td>\n",
       "      <td>[Motivated, by, the, success, of, ensemble, me...</td>\n",
       "      <td>[O, O, O, O, O, O, B, I, O, B, I, O, O, O, O, ...</td>\n",
       "      <td>[VBN, IN, DT, NN, IN, JJ, NNS, IN, NN, NN, CC,...</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTERSPEECH_2006_28_abs</td>\n",
       "      <td>We investigated whether automatic phonetic tra...</td>\n",
       "      <td>[We, investigated, whether, automatic, phoneti...</td>\n",
       "      <td>[O, O, O, B, I, I, I, O, O, B, I, I, I, O, O, ...</td>\n",
       "      <td>[PRP, VBD, IN, JJ, JJ, NNS, VBP, MD, VB, RB, V...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICCV_1999_47_abs</td>\n",
       "      <td>Background maintenance is a frequent element o...</td>\n",
       "      <td>[Background, maintenance, is, a, frequent, ele...</td>\n",
       "      <td>[B, I, I, I, I, O, O, O, O, B, I, I, O, B, I, ...</td>\n",
       "      <td>[NNP, NN, VBZ, DT, JJ, NN, IN, NN, NN, NN, PRP...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICCV_2011_47_abs</td>\n",
       "      <td>We present a method for detecting 3D objects u...</td>\n",
       "      <td>[We, present, a, method, for, detecting, 3D, o...</td>\n",
       "      <td>[O, O, O, B, O, B, I, I, O, B, O, B, O, O, O, ...</td>\n",
       "      <td>[PRP, VBP, DT, NN, IN, VBG, CD, NNS, VBG, NN, ...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVPR_2016_416_abs</td>\n",
       "      <td>We investigate the problem of fine-grained ske...</td>\n",
       "      <td>[We, investigate, the, problem, of, fine-grain...</td>\n",
       "      <td>[O, O, O, O, O, B, I, I, I, I, O, B, I, I, O, ...</td>\n",
       "      <td>[PRP, VBP, DT, NN, IN, JJ, JJ, NN, NN, NNP, WR...</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>H93-1076</td>\n",
       "      <td>Two themes have evolved in  speech and text im...</td>\n",
       "      <td>[Two, themes, have, evolved, in, speech, and, ...</td>\n",
       "      <td>[O, O, B, O, O, O, B, I, I, I, I, O, O, O, O, ...</td>\n",
       "      <td>[CD, NNS, VBP, VBN, IN, NN, CC, JJ, NN, NN, NN...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>CVPR_1996_15_abs</td>\n",
       "      <td>We previously presented a framework for segmen...</td>\n",
       "      <td>[We, previously, presented, a, framework, for,...</td>\n",
       "      <td>[O, O, O, O, B, O, B, I, I, I, O, O, B, I, O, ...</td>\n",
       "      <td>[PRP, RB, VBD, DT, NN, IN, NN, IN, JJ, NNS, VB...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ICASSP_2011_588_abs</td>\n",
       "      <td>In a motorized vehicle a number of easily meas...</td>\n",
       "      <td>[In, a, motorized, vehicle, a, number, of, eas...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, O, B, I, O, O, ...</td>\n",
       "      <td>[IN, DT, JJ, NN, DT, NN, IN, RB, JJ, NNS, IN, ...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>H90-1011</td>\n",
       "      <td>This paper describes a particular approach to ...</td>\n",
       "      <td>[This, paper, describes, a, particular, approa...</td>\n",
       "      <td>[O, O, O, O, O, O, B, O, B, O, O, O, O, O, B, ...</td>\n",
       "      <td>[DT, NN, VBZ, DT, JJ, NN, TO, VBG, IN, JJ, JJ,...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>NIPS_2001_11_abs</td>\n",
       "      <td>A mixed-signal paradigm is presented for high-...</td>\n",
       "      <td>[A, mixed-signal, paradigm, is, presented, for...</td>\n",
       "      <td>[O, B, I, O, O, O, B, I, I, I, O, O, O, O, O, ...</td>\n",
       "      <td>[DT, JJ, NN, VBZ, VBN, IN, NN, JJ, NN, NN, IN,...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sentence_id  \\\n",
       "0                   N03-1004   \n",
       "1    INTERSPEECH_2006_28_abs   \n",
       "2           ICCV_1999_47_abs   \n",
       "3           ICCV_2011_47_abs   \n",
       "4          CVPR_2016_416_abs   \n",
       "..                       ...   \n",
       "495                 H93-1076   \n",
       "496         CVPR_1996_15_abs   \n",
       "497      ICASSP_2011_588_abs   \n",
       "498                 H90-1011   \n",
       "499         NIPS_2001_11_abs   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    Motivated by the success of  ensemble methods ...   \n",
       "1    We investigated whether automatic phonetic tra...   \n",
       "2    Background maintenance is a frequent element o...   \n",
       "3    We present a method for detecting 3D objects u...   \n",
       "4    We investigate the problem of fine-grained ske...   \n",
       "..                                                 ...   \n",
       "495  Two themes have evolved in  speech and text im...   \n",
       "496  We previously presented a framework for segmen...   \n",
       "497  In a motorized vehicle a number of easily meas...   \n",
       "498  This paper describes a particular approach to ...   \n",
       "499  A mixed-signal paradigm is presented for high-...   \n",
       "\n",
       "                                                 words  \\\n",
       "0    [Motivated, by, the, success, of, ensemble, me...   \n",
       "1    [We, investigated, whether, automatic, phoneti...   \n",
       "2    [Background, maintenance, is, a, frequent, ele...   \n",
       "3    [We, present, a, method, for, detecting, 3D, o...   \n",
       "4    [We, investigate, the, problem, of, fine-grain...   \n",
       "..                                                 ...   \n",
       "495  [Two, themes, have, evolved, in, speech, and, ...   \n",
       "496  [We, previously, presented, a, framework, for,...   \n",
       "497  [In, a, motorized, vehicle, a, number, of, eas...   \n",
       "498  [This, paper, describes, a, particular, approa...   \n",
       "499  [A, mixed-signal, paradigm, is, presented, for...   \n",
       "\n",
       "                                                   BIO  \\\n",
       "0    [O, O, O, O, O, O, B, I, O, B, I, O, O, O, O, ...   \n",
       "1    [O, O, O, B, I, I, I, O, O, B, I, I, I, O, O, ...   \n",
       "2    [B, I, I, I, I, O, O, O, O, B, I, I, O, B, I, ...   \n",
       "3    [O, O, O, B, O, B, I, I, O, B, O, B, O, O, O, ...   \n",
       "4    [O, O, O, O, O, B, I, I, I, I, O, B, I, I, O, ...   \n",
       "..                                                 ...   \n",
       "495  [O, O, B, O, O, O, B, I, I, I, I, O, O, O, O, ...   \n",
       "496  [O, O, O, O, B, O, B, I, I, I, O, O, B, I, O, ...   \n",
       "497  [O, O, O, O, O, O, O, O, B, I, O, B, I, O, O, ...   \n",
       "498  [O, O, O, O, O, O, B, O, B, O, O, O, O, O, B, ...   \n",
       "499  [O, B, I, O, O, O, B, I, I, I, O, O, O, O, O, ...   \n",
       "\n",
       "                                                   POS  length  \n",
       "0    [VBN, IN, DT, NN, IN, JJ, NNS, IN, NN, NN, CC,...     124  \n",
       "1    [PRP, VBD, IN, JJ, JJ, NNS, VBP, MD, VB, RB, V...     136  \n",
       "2    [NNP, NN, VBZ, DT, JJ, NN, IN, NN, NN, NN, PRP...     104  \n",
       "3    [PRP, VBP, DT, NN, IN, VBG, CD, NNS, VBG, NN, ...      86  \n",
       "4    [PRP, VBP, DT, NN, IN, JJ, JJ, NN, NN, NNP, WR...     176  \n",
       "..                                                 ...     ...  \n",
       "495  [CD, NNS, VBP, VBN, IN, NN, CC, JJ, NN, NN, NN...     126  \n",
       "496  [PRP, RB, VBD, DT, NN, IN, NN, IN, JJ, NNS, VB...     117  \n",
       "497  [IN, DT, JJ, NN, DT, NN, IN, RB, JJ, NNS, IN, ...     146  \n",
       "498  [DT, NN, VBZ, DT, JJ, NN, TO, VBG, IN, JJ, JJ,...     147  \n",
       "499  [DT, JJ, NN, VBZ, VBN, IN, NN, JJ, NN, NN, IN,...      98  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrase.to_csv(\"Dataset_TaskB/SCIERC_Paragraphs.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrase = pd.read_csv(\"Dataset_TaskB/SCIERC_Paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval as load\n",
    "def NER_format(df):\n",
    "    shift = 0\n",
    "    words = []\n",
    "    sentence_id = []\n",
    "    labels = []\n",
    "    pos_tag = []\n",
    "    for i in range(len(df)):\n",
    "        word = load(df.iloc[i,2])\n",
    "        BIO = load(df.iloc[i,3])\n",
    "        pos = load(df.iloc[i,4])\n",
    "        sentence_id.extend([i+shift]*len(word))\n",
    "        words.extend(word)\n",
    "        labels.extend(BIO)\n",
    "        pos_tag.extend(pos)\n",
    "    return sentence_id, words, labels, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_id, words, labels, pos_tag = NER_format(df_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels, \"pos_tag\" : pos_tag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentence_id'] < 496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset_TaskB/scierc_paragraphs_phrases.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset_TaskB/scierc_paragraphs_phrases.csv\")\n",
    "df.dropna(subset = ['words', 'labels'], inplace = True)\n",
    "df.to_csv(\"Dataset_TaskB/scierc_paragraphs_phrases.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121.46"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase['length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval as load\n",
    "def NER_format(df):\n",
    "    words = []\n",
    "    sentence_id = []\n",
    "    labels = []\n",
    "    pos_tag = []\n",
    "    index = 0\n",
    "    for i in range(len(df)):\n",
    "        word = load(df.iloc[i,2])\n",
    "        BIO = load(df.iloc[i,3])\n",
    "        pos = load(df.iloc[i,4])\n",
    "        words.extend(word)\n",
    "        labels.extend(BIO)\n",
    "        pos_tag.extend(pos)\n",
    "    for word in words:\n",
    "        sentence_id.append(index)\n",
    "        if(word.endswith('.')):\n",
    "            index += 1\n",
    "    print(index)\n",
    "    return sentence_id, words, labels, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2715\n"
     ]
    }
   ],
   "source": [
    "sentence_id, words, labels, pos_tag = NER_format(df_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels, \"pos_tag\" : pos_tag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>methods</td>\n",
       "      <td>B</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>learning</td>\n",
       "      <td>B</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>language</td>\n",
       "      <td>B</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>B</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>agents</td>\n",
       "      <td>B</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60700</th>\n",
       "      <td>2713</td>\n",
       "      <td>near-Bernoulli</td>\n",
       "      <td>B</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60704</th>\n",
       "      <td>2713</td>\n",
       "      <td>highly</td>\n",
       "      <td>B</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60708</th>\n",
       "      <td>2714</td>\n",
       "      <td>approach</td>\n",
       "      <td>B</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60712</th>\n",
       "      <td>2714</td>\n",
       "      <td>real</td>\n",
       "      <td>B</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60721</th>\n",
       "      <td>2714</td>\n",
       "      <td>CID/DRAM</td>\n",
       "      <td>B</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7020 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id           words labels pos_tag\n",
       "6                0         methods      B     NNS\n",
       "9                0        learning      B      NN\n",
       "15               0        language      B      NN\n",
       "22               0             and      B      CC\n",
       "38               0          agents      B     NNS\n",
       "...            ...             ...    ...     ...\n",
       "60700         2713  near-Bernoulli      B      JJ\n",
       "60704         2713          highly      B      RB\n",
       "60708         2714        approach      B      NN\n",
       "60712         2714            real      B      JJ\n",
       "60721         2714        CID/DRAM      B     NNP\n",
       "\n",
       "[7020 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['labels'] == 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentence_id'] < 2704]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset_TaskB/scierc_sent_phrases.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset_TaskB/scierc_sent_phrases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['words', 'labels'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset_TaskB/scierc_sent_phrases.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('TDMSci.txt', 'r')\n",
    "lines = file.readlines()\n",
    "sentence_id = []\n",
    "words = []\n",
    "labels = []\n",
    "sent_id = 0\n",
    "for line in lines:\n",
    "    tokens = line.split('\\t')\n",
    "    if(len(tokens) < 3):\n",
    "        sent_id += 1\n",
    "    else:\n",
    "        sentence_id.append(sent_id)\n",
    "        words.append(tokens[0])\n",
    "        labels.append(tokens[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentence_id'] < 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset_TaskB/TDMSci_dataset.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(tokens):\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tags = [x[1] for x in tags]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_TDMSci():\n",
    "    df = pd.read_csv(\"Dataset_TaskB/TDMSci_dataset.csv\")\n",
    "    df.dropna(subset = ['words', 'labels'], inplace = True)\n",
    "    sentences = df.groupby(\"sentence_id\")[\"words\"].apply(list).values\n",
    "    pos_tag = []\n",
    "    for sent in sentences:\n",
    "        tags = tag(sent)\n",
    "        pos_tag.extend(tags)\n",
    "    df['pos_tag'] = pos_tag\n",
    "    df.to_csv(\"Dataset_TaskB/TDMSci_dataset.csv\", index = None)\n",
    "process_data_TDMSci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset_TaskB/TDMSci_dataset.csv\")\n",
    "df.dropna(subset = ['words', 'labels'], inplace = True)\n",
    "df.to_csv(\"Dataset_TaskB/TDMSci_dataset.csv\", index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
