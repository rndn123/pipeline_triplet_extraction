{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def tag(x):\n",
    "    tokens = x.split()\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tags = [x[1] for x in tags]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_integers(filename):\n",
    "    with open(filename) as f:\n",
    "        return [int(x) for x in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constituency_parsing 8\n",
      "constituency_parsing 1\n",
      "constituency_parsing 5\n",
      "constituency_parsing 7\n",
      "constituency_parsing 4\n",
      "constituency_parsing 6\n",
      "constituency_parsing 2\n",
      "constituency_parsing 3\n",
      "constituency_parsing 0\n",
      "entity_linking 16\n",
      "entity_linking 13\n",
      "entity_linking 8\n",
      "entity_linking 9\n",
      "entity_linking 1\n",
      "entity_linking 5\n",
      "entity_linking 11\n",
      "entity_linking 14\n",
      "entity_linking 7\n",
      "entity_linking 4\n",
      "entity_linking 6\n",
      "entity_linking 10\n",
      "entity_linking 2\n",
      "entity_linking 3\n",
      "entity_linking 15\n",
      "entity_linking 12\n",
      "entity_linking 0\n",
      "face_detection 16\n",
      "face_detection 13\n",
      "face_detection 8\n",
      "face_detection 9\n",
      "face_detection 1\n",
      "face_detection 21\n",
      "face_detection 5\n",
      "face_detection 11\n",
      "face_detection 14\n",
      "face_detection 7\n",
      "face_detection 19\n",
      "face_detection 20\n",
      "face_detection 18\n",
      "face_detection 4\n",
      "face_detection 6\n",
      "face_detection 10\n",
      "face_detection 17\n",
      "face_detection 2\n",
      "face_detection 3\n",
      "face_detection 15\n",
      "face_detection 12\n",
      "face_detection 0\n",
      "coreference_resolution 8\n",
      "coreference_resolution 9\n",
      "coreference_resolution 1\n",
      "coreference_resolution 5\n",
      "coreference_resolution 7\n",
      "coreference_resolution 4\n",
      "coreference_resolution 6\n",
      "coreference_resolution 2\n",
      "coreference_resolution 3\n",
      "coreference_resolution 0\n",
      "dependency_parsing 8\n",
      "dependency_parsing 1\n",
      "dependency_parsing 5\n",
      "dependency_parsing 7\n",
      "dependency_parsing 4\n",
      "dependency_parsing 6\n",
      "dependency_parsing 2\n",
      "dependency_parsing 3\n",
      "dependency_parsing 0\n",
      "face_alignment 16\n",
      "face_alignment 13\n",
      "face_alignment 8\n",
      "face_alignment 9\n",
      "face_alignment 1\n",
      "face_alignment 5\n",
      "face_alignment 11\n",
      "face_alignment 14\n",
      "face_alignment 7\n",
      "face_alignment 18\n",
      "face_alignment 4\n",
      "face_alignment 6\n",
      "face_alignment 10\n",
      "face_alignment 17\n",
      "face_alignment 2\n",
      "face_alignment 3\n",
      "face_alignment 15\n",
      "face_alignment 12\n",
      "face_alignment 0\n",
      "natural_language_inference 16\n",
      "natural_language_inference 13\n",
      "natural_language_inference 27\n",
      "natural_language_inference 8\n",
      "natural_language_inference 9\n",
      "natural_language_inference 25\n",
      "natural_language_inference 26\n",
      "natural_language_inference 1\n",
      "natural_language_inference 21\n",
      "natural_language_inference 5\n",
      "natural_language_inference 11\n",
      "natural_language_inference 23\n",
      "natural_language_inference 24\n",
      "natural_language_inference 14\n",
      "natural_language_inference 7\n",
      "natural_language_inference 28\n",
      "natural_language_inference 19\n",
      "natural_language_inference 20\n",
      "natural_language_inference 18\n",
      "natural_language_inference 4\n",
      "natural_language_inference 6\n",
      "natural_language_inference 10\n",
      "natural_language_inference 29\n",
      "natural_language_inference 17\n",
      "natural_language_inference 2\n",
      "natural_language_inference 3\n",
      "natural_language_inference 15\n",
      "natural_language_inference 22\n",
      "natural_language_inference 30\n",
      "natural_language_inference 31\n",
      "natural_language_inference 12\n",
      "natural_language_inference 0\n",
      "document_classification 16\n",
      "document_classification 13\n",
      "document_classification 8\n",
      "document_classification 9\n",
      "document_classification 1\n",
      "document_classification 5\n",
      "document_classification 11\n",
      "document_classification 14\n",
      "document_classification 7\n",
      "document_classification 19\n",
      "document_classification 20\n",
      "document_classification 18\n",
      "document_classification 4\n",
      "document_classification 6\n",
      "document_classification 10\n",
      "document_classification 17\n",
      "document_classification 2\n",
      "document_classification 3\n",
      "document_classification 15\n",
      "document_classification 12\n",
      "document_classification 0\n",
      "data-to-text_generation 1\n",
      "data-to-text_generation 5\n",
      "data-to-text_generation 4\n",
      "data-to-text_generation 6\n",
      "data-to-text_generation 2\n",
      "data-to-text_generation 3\n",
      "data-to-text_generation 0\n",
      "hypernym_discovery 8\n",
      "hypernym_discovery 1\n",
      "hypernym_discovery 5\n",
      "hypernym_discovery 7\n",
      "hypernym_discovery 4\n",
      "hypernym_discovery 6\n",
      "hypernym_discovery 2\n",
      "hypernym_discovery 3\n",
      "hypernym_discovery 0\n"
     ]
    }
   ],
   "source": [
    "path = \"./NCG_Dataset/test-data/*/*\"\n",
    "directory = glob.glob(path)\n",
    "position = len(path)-3\n",
    "topics, paper_ID, sentence_ID = [], [], []\n",
    "sentences, list_words, BIO, POS, length = [], [], [], [], []\n",
    "for dir in directory:\n",
    "    file1 = \"\".join((dir,\"/*-Stanza-out.txt\"))\n",
    "    file2 = \"\".join((dir,\"/sentences.txt\"))\n",
    "    file3 = \"\".join((dir,\"/new_entities.txt\"))\n",
    "    file11 = glob.glob(file1)\n",
    "    file22 = glob.glob(file2)\n",
    "    file33 = glob.glob(file3)\n",
    "    with open(file11[0], encoding='ISO-8859-1') as f:\n",
    "        lines = f.readlines()\n",
    "    sent = read_integers(file22[0])\n",
    "    sent.sort()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    pos = dir.find('/', position)\n",
    "    topic = dir[position:pos]\n",
    "    ID = dir[pos+1:len(dir)]\n",
    "    text = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if i+1 in sent:\n",
    "            text.append(line)\n",
    "    with open(file33[0], encoding='ISO-8859-1') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    triplets = []\n",
    "    for line in lines:\n",
    "        item = line.split()\n",
    "        if (len(item)<4):\n",
    "            continue\n",
    "        triplets.append([int(item[0]), int(item[1]), int(item[2]), item[3]])\n",
    "    triplets.sort()\n",
    "    index = 0\n",
    "    print(topic, ID)\n",
    "    #print(triplets)\n",
    "    for i, sentence in enumerate(text):\n",
    "        words = sentence.split()\n",
    "        sent_ID = sent[i]\n",
    "        cur = 0\n",
    "        labels = []\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            label = 'O'\n",
    "            if(index<len(triplets) and triplets[index][0] == sent_ID and cur > triplets[index][2]):\n",
    "                index += 1\n",
    "            if(index >= len(triplets) or triplets[index][0] > sent_ID):\n",
    "                label = 'O'\n",
    "            elif(cur == triplets[index][1]):\n",
    "                label = 'B-'+triplets[index][3]\n",
    "            elif(cur >  triplets[index][1]):\n",
    "                label = 'I-'+triplets[index][3]\n",
    "            else:\n",
    "                label = 'O'\n",
    "            cur = cur + 1 + len(word)\n",
    "            labels.append(label)\n",
    "        pos = tag(sentence)\n",
    "        if(index<len(triplets) and triplets[index][0] == sent_ID):\n",
    "            index += 1\n",
    "        topics.append(topic)\n",
    "        paper_ID.append(ID)\n",
    "        sentence_ID.append(sent_ID)\n",
    "        sentences.append(sentence)\n",
    "        list_words.append(words)\n",
    "        BIO.append(labels)\n",
    "        POS.append(pos)\n",
    "        length.append(len(words))\n",
    "df_phrase = pd.DataFrame({\"topic\" : topics, \"paper_ID\" : paper_ID, \"sentence_ID\" : sentence_ID,\n",
    "    'sentence' : sentences, 'words': list_words, 'BIO' : BIO, 'POS': POS, 'length' : length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>paper_ID</th>\n",
       "      <th>sentence_ID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "      <th>BIO</th>\n",
       "      <th>POS</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Constituency Parsing with a Self - Attentive E...</td>\n",
       "      <td>[Constituency, Parsing, with, a, Self, -, Atte...</td>\n",
       "      <td>[B-n, I-n, O, O, O, O, O, O]</td>\n",
       "      <td>[NN, VBG, IN, DT, NNP, :, JJ, NN]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>In this paper , we introduce a parser that com...</td>\n",
       "      <td>[In, this, paper, ,, we, introduce, a, parser,...</td>\n",
       "      <td>[O, O, O, O, O, B-p, O, B-n, O, B-p, O, B-n, B...</td>\n",
       "      <td>[IN, DT, NN, ,, PRP, VBP, DT, NN, WDT, VBZ, DT...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>We also present a version of our model that us...</td>\n",
       "      <td>[We, also, present, a, version, of, our, model...</td>\n",
       "      <td>[O, O, B-p, B-n, I-n, I-n, I-n, I-n, O, B-p, O...</td>\n",
       "      <td>[PRP, RB, VBD, DT, NN, IN, PRP$, NN, WDT, VBZ,...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>163</td>\n",
       "      <td>6 Results</td>\n",
       "      <td>[6, Results]</td>\n",
       "      <td>[O, B-n]</td>\n",
       "      <td>[CD, NNS]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>8</td>\n",
       "      <td>164</td>\n",
       "      <td>English ( WSJ )</td>\n",
       "      <td>[English, (, WSJ, )]</td>\n",
       "      <td>[B-n, I-n, I-n, I-n]</td>\n",
       "      <td>[NNP, (, NNP, )]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Even though unsupervised systems tend to rank ...</td>\n",
       "      <td>[Even, though, unsupervised, systems, tend, to...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[RB, IN, JJ, NNS, VBP, TO, VB, IN, JJ, NNS, IN...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Results</td>\n",
       "      <td>[Results]</td>\n",
       "      <td>[B-n]</td>\n",
       "      <td>[NNS]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>Our official submission ranked at eleven out o...</td>\n",
       "      <td>[Our, official, submission, ranked, at, eleven...</td>\n",
       "      <td>[B-n, I-n, I-n, B-p, O, B-n, B-p, I-p, B-n, B-...</td>\n",
       "      <td>[PRP$, JJ, NN, VBD, IN, VBN, IN, IN, NN, IN, D...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>However , it ranked first place among all the ...</td>\n",
       "      <td>[However, ,, it, ranked, first, place, among, ...</td>\n",
       "      <td>[O, O, O, O, B-n, I-n, B-p, B-n, I-n, I-n, I-n...</td>\n",
       "      <td>[RB, ,, PRP, VBD, JJ, NN, IN, PDT, DT, JJ, NNS...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>hypernym_discovery</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>On the music industry domain subtask , our sys...</td>\n",
       "      <td>[On, the, music, industry, domain, subtask, ,,...</td>\n",
       "      <td>[B-p, O, B-n, I-n, I-n, I-n, O, B-n, I-n, B-p,...</td>\n",
       "      <td>[IN, DT, NN, NN, NN, NN, ,, PRP$, NN, VBD, CD,...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2720 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     topic paper_ID  sentence_ID  \\\n",
       "0     constituency_parsing        8            2   \n",
       "1     constituency_parsing        8           16   \n",
       "2     constituency_parsing        8           24   \n",
       "3     constituency_parsing        8          163   \n",
       "4     constituency_parsing        8          164   \n",
       "...                    ...      ...          ...   \n",
       "2715    hypernym_discovery        0           25   \n",
       "2716    hypernym_discovery        0           60   \n",
       "2717    hypernym_discovery        0           61   \n",
       "2718    hypernym_discovery        0           62   \n",
       "2719    hypernym_discovery        0           63   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     Constituency Parsing with a Self - Attentive E...   \n",
       "1     In this paper , we introduce a parser that com...   \n",
       "2     We also present a version of our model that us...   \n",
       "3                                             6 Results   \n",
       "4                                       English ( WSJ )   \n",
       "...                                                 ...   \n",
       "2715  Even though unsupervised systems tend to rank ...   \n",
       "2716                                            Results   \n",
       "2717  Our official submission ranked at eleven out o...   \n",
       "2718  However , it ranked first place among all the ...   \n",
       "2719  On the music industry domain subtask , our sys...   \n",
       "\n",
       "                                                  words  \\\n",
       "0     [Constituency, Parsing, with, a, Self, -, Atte...   \n",
       "1     [In, this, paper, ,, we, introduce, a, parser,...   \n",
       "2     [We, also, present, a, version, of, our, model...   \n",
       "3                                          [6, Results]   \n",
       "4                                  [English, (, WSJ, )]   \n",
       "...                                                 ...   \n",
       "2715  [Even, though, unsupervised, systems, tend, to...   \n",
       "2716                                          [Results]   \n",
       "2717  [Our, official, submission, ranked, at, eleven...   \n",
       "2718  [However, ,, it, ranked, first, place, among, ...   \n",
       "2719  [On, the, music, industry, domain, subtask, ,,...   \n",
       "\n",
       "                                                    BIO  \\\n",
       "0                          [B-n, I-n, O, O, O, O, O, O]   \n",
       "1     [O, O, O, O, O, B-p, O, B-n, O, B-p, O, B-n, B...   \n",
       "2     [O, O, B-p, B-n, I-n, I-n, I-n, I-n, O, B-p, O...   \n",
       "3                                              [O, B-n]   \n",
       "4                                  [B-n, I-n, I-n, I-n]   \n",
       "...                                                 ...   \n",
       "2715  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2716                                              [B-n]   \n",
       "2717  [B-n, I-n, I-n, B-p, O, B-n, B-p, I-p, B-n, B-...   \n",
       "2718  [O, O, O, O, B-n, I-n, B-p, B-n, I-n, I-n, I-n...   \n",
       "2719  [B-p, O, B-n, I-n, I-n, I-n, O, B-n, I-n, B-p,...   \n",
       "\n",
       "                                                    POS  length  \n",
       "0                     [NN, VBG, IN, DT, NNP, :, JJ, NN]       8  \n",
       "1     [IN, DT, NN, ,, PRP, VBP, DT, NN, WDT, VBZ, DT...      30  \n",
       "2     [PRP, RB, VBD, DT, NN, IN, PRP$, NN, WDT, VBZ,...      30  \n",
       "3                                             [CD, NNS]       2  \n",
       "4                                      [NNP, (, NNP, )]       4  \n",
       "...                                                 ...     ...  \n",
       "2715  [RB, IN, JJ, NNS, VBP, TO, VB, IN, JJ, NNS, IN...      59  \n",
       "2716                                              [NNS]       1  \n",
       "2717  [PRP$, JJ, NN, VBD, IN, VBN, IN, IN, NN, IN, D...      25  \n",
       "2718  [RB, ,, PRP, VBD, JJ, NN, IN, PDT, DT, JJ, NNS...      15  \n",
       "2719  [IN, DT, NN, NN, NN, NN, ,, PRP$, NN, VBD, CD,...      28  \n",
       "\n",
       "[2720 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrase.to_csv(\"Test_Phrases.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase['length'].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
